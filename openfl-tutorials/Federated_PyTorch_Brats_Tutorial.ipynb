{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "figured-aspect",
   "metadata": {},
   "source": [
    "# Federated PyTorch 3dUNET Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-puppy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-parameter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openfl.native as fx\n",
    "\n",
    "# Setup default workspace, logging, etc. Install additional requirements\n",
    "fx.init('torch_3dunet_brats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dirty-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from openfl.federated import FederatedModel, FederatedDataSet\n",
    "from openfl.utilities import TensorKey\n",
    "from openfl.component.aggregation_functions import AggregationFunctionInterface\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-school",
   "metadata": {},
   "source": [
    "Path to brats dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pursuant-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRATS_PATH = './data/MICCAI_BraTS2020_TrainingData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-excuse",
   "metadata": {},
   "source": [
    "Lets define dataset, which will get data_list brain tumor images for one collaborator (train or validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "boolean-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSDataset():\n",
    "    \"\"\"\n",
    "    This dataset contains brain tumor 3d images for one collaborator train or val.\n",
    "    Args:\n",
    "        data_list: list of image paths\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        images = []\n",
    "        for i in range(1, 5):\n",
    "            img = nib.load(self.data_list[index]['image{}'.format(i)])\n",
    "            img = np.asanyarray(img.dataobj)\n",
    "            img = self.resize(img, (160, 160, 128))\n",
    "            img = self.normalize(img)\n",
    "            images.append(img)\n",
    "        img = np.stack(images)\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        mask = nib.load(self.data_list[index]['label'])\n",
    "        mask = np.asanyarray(mask.dataobj)\n",
    "        mask = self.resize(mask, (160, 160, 128)).astype(np.uint8)\n",
    "        mask = self.classify(mask)\n",
    "        return (img, mask)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        data_min = np.min(data)\n",
    "        return (data - data_min) / (np.max(data) - data_min)\n",
    "\n",
    "    def resize(self, data, sizes):\n",
    "        data = resize(data, sizes, mode='edge',\n",
    "                      anti_aliasing=False,\n",
    "                      anti_aliasing_sigma=None,\n",
    "                      preserve_range=True,\n",
    "                      order=0)\n",
    "        return data\n",
    "\n",
    "    def classify(self, inputs):\n",
    "        result = []\n",
    "        # merge label 2 and label 3 to construct TC\n",
    "        result.append(np.logical_or(inputs == 2, inputs == 3))\n",
    "        # merge labels 1, 2 and 3 to construct WT\n",
    "        result.append(\n",
    "            np.logical_or(\n",
    "                np.logical_or(inputs == 2, inputs == 3), inputs == 1\n",
    "            )\n",
    "        )\n",
    "        # label 2 is ET\n",
    "        result.append(inputs == 2)\n",
    "        return np.stack(result, axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-firmware",
   "metadata": {},
   "source": [
    "Wrapper, to define generate_*_list interfaces. Further it will be replaced by another function to pass test data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "urban-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FederatedDataSetWrapper(FederatedDataSet):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "        self.train_list = self.generate_train_list(*args, **kwargs)\n",
    "        self.val_list = self.generate_val_list(*args, **kwargs)\n",
    "        super().__init__([], [], [], [], 1, **kwargs)\n",
    "\n",
    "    def generate_train_list(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def generate_val_list(self, *args, **kwargs):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-excitement",
   "metadata": {},
   "source": [
    "Here we redefine `FederatedDataSet` methods, if we don't want to use default batch generator from `FederatedDataSet`.<br> Also we should override `generate_train_list` and `generate_val_list` methods.<br> We should use `self.train_list` and `self.val_list` form `FederatedDataSetWrapper` as data paths, because such pipeline will be use with test data. This fields will be initialized after calling `FederatedDataSetWrapper` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c171e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSFederatedDataset(FederatedDataSetWrapper):\n",
    "    def __init__(self, collaborator_count=1, collaborator_num=0,\n",
    "                 batch_size=1, data_list=[], **kwargs):\n",
    "        \"\"\"Instantiate the federated data object\n",
    "        Args:\n",
    "            collaborator_count: total number of collaborators\n",
    "            collaborator_num: number of current collaborator\n",
    "            batch_size:  the batch size of the data loader\n",
    "            data_list: general list of all image paths, in current implementation\n",
    "                it should be created once so that each colaborator gets its own data\n",
    "            **kwargs: additional arguments, passed to super init\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        # Call super().__init__ to call generate_*_list methods,\n",
    "        # so self.train_list and val_list fields will be initialized\n",
    "        # You should use this fields as data paths, because such pipeline\n",
    "        # will be use with test data.\n",
    "        super().__init__(collaborator_count, collaborator_num, num_classes=2, **kwargs)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.training_set = BraTSDataset(self.train_list)\n",
    "        self.valid_set = BraTSDataset(self.val_list)\n",
    "\n",
    "        self.train_loader = self.get_train_loader()\n",
    "        self.val_loader = self.get_valid_loader()\n",
    "\n",
    "    def generate_name_list(self, collaborator_count, collaborator_num, is_validation):\n",
    "        if self.data_list == []:\n",
    "            data_dir = BRATS_PATH\n",
    "            self.data_list = [\n",
    "                {\n",
    "                    'image1': data_dir + 'BraTS20_Training_' + str(i)[1:] + '/BraTS20_Training_' + str(i)[1:] + '_flair.nii.gz',\n",
    "                    'image2': data_dir + 'BraTS20_Training_' + str(i)[1:] + '/BraTS20_Training_' + str(i)[1:] + '_t1ce.nii.gz',\n",
    "                    'image3': data_dir + 'BraTS20_Training_' + str(i)[1:] + '/BraTS20_Training_' + str(i)[1:] + '_t1.nii.gz',\n",
    "                    'image4': data_dir + 'BraTS20_Training_' + str(i)[1:] + '/BraTS20_Training_' + str(i)[1:] + '_t2.nii.gz',\n",
    "                    'label': data_dir + 'BraTS20_Training_' + str(i)[1:] + '/BraTS20_Training_' + str(i)[1:] + '_seg.nii.gz'\n",
    "                } for i in range(1001, 1370)]\n",
    "            random.shuffle(self.data_list)\n",
    "\n",
    "        # split all data for current collaborator\n",
    "        data = self.data_list[collaborator_num:: collaborator_count]\n",
    "        assert(len(data) > 7)\n",
    "        validation_size = len(data) // 7\n",
    "        if is_validation:\n",
    "            data = data[-validation_size:]\n",
    "        else:\n",
    "            data = data[: -validation_size]\n",
    "        return data\n",
    "\n",
    "    # Override--------------------------------------------------------------------------\n",
    "    def generate_train_list(self, collaborator_count, collaborator_num, *args, **kwargs):\n",
    "        return self.generate_name_list(collaborator_count, collaborator_num, False)\n",
    "\n",
    "    def generate_val_list(self, collaborator_count, collaborator_num, *args, **kwargs):\n",
    "        return self.generate_name_list(collaborator_count, collaborator_num, True)\n",
    "    # -----------------------------------------------------------------------------------\n",
    "\n",
    "    def get_valid_loader(self, num_batches=None):\n",
    "        return DataLoader(self.valid_set, num_workers=6, batch_size=self.batch_size)\n",
    "\n",
    "    def get_train_loader(self, num_batches=None):\n",
    "        return DataLoader(\n",
    "            self.training_set, num_workers=6, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        return len(self.training_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        return len(self.valid_set)\n",
    "\n",
    "    def get_feature_shape(self):\n",
    "        return self.valid_set[0][0].shape\n",
    "\n",
    "    def split(self, collaborator_count, shuffle=True, equally=True):\n",
    "        return [\n",
    "            BraTSFederatedDataset(collaborator_count,\n",
    "                                  collaborator_num, self.batch_size, self.data_list)\n",
    "            for collaborator_num in range(collaborator_count)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-seeker",
   "metadata": {},
   "source": [
    "Our Unet model. Define `validate` method, to use special metric (default metric - accuracy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lucky-bracelet",
   "metadata": {
    "code_folding": [
     19,
     40,
     53
    ]
   },
   "outputs": [],
   "source": [
    "def soft_dice_loss(output, target):\n",
    "    num = target.size(0)\n",
    "    m1 = output.view(num, -1)\n",
    "    m2 = target.view(num, -1)\n",
    "    intersection = m1 * m2\n",
    "    score = 2.0 * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)\n",
    "    score = 1 - score.sum() / num\n",
    "    return score\n",
    "\n",
    "\n",
    "def soft_dice_coef(output, target):\n",
    "    num = target.size(0)\n",
    "    m1 = output.view(num, -1)\n",
    "    m2 = target.view(num, -1)\n",
    "    intersection = m1 * m2\n",
    "    score = 2.0 * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)\n",
    "    return score.sum()\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv3D -> BN -> ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(out_channels, out_channels,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool3d(2, 2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(\n",
    "                scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(\n",
    "                in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY //\n",
    "                        2, diffY - diffY // 2, diffZ // 2, diffZ - diffZ // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Out(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet3d(nn.Module):\n",
    "    def __init__(self, in_channels=4, n_classes=3, n_channels=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, n_channels)\n",
    "        self.enc1 = Down(n_channels, 2 * n_channels)\n",
    "        self.enc2 = Down(2 * n_channels, 4 * n_channels)\n",
    "        self.enc3 = Down(4 * n_channels, 8 * n_channels)\n",
    "        self.enc4 = Down(8 * n_channels, 8 * n_channels)\n",
    "\n",
    "        self.dec1 = Up(16 * n_channels, 4 * n_channels)\n",
    "        self.dec2 = Up(8 * n_channels, 2 * n_channels)\n",
    "        self.dec3 = Up(4 * n_channels, n_channels)\n",
    "        self.dec4 = Up(2 * n_channels, n_channels)\n",
    "        self.out = Out(n_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv(x)\n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        x5 = self.enc4(x4)\n",
    "\n",
    "        mask = self.dec1(x5, x4)\n",
    "        mask = self.dec2(mask, x3)\n",
    "        mask = self.dec3(mask, x2)\n",
    "        mask = self.dec4(mask, x1)\n",
    "        mask = self.out(mask)\n",
    "        mask = torch.sigmoid(mask)\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def validate(\n",
    "        self, col_name, round_num, input_tensor_dict, use_tqdm=False, **kwargs\n",
    "    ):\n",
    "        \"\"\" Validate. Redifine function from PyTorchTaskRunner, to use our validation\"\"\"\n",
    "        self.rebuild_model(round_num, input_tensor_dict, validation=True)\n",
    "        loader = self.data_loader.get_valid_loader()\n",
    "        if use_tqdm:\n",
    "            loader = tqdm(loader, desc=\"validate\")\n",
    "    # -------------Usual validation code-----------------------------------------------\n",
    "        self.eval()\n",
    "        self.to(self.device)\n",
    "        metric = 0.0\n",
    "        sample_num = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in loader:\n",
    "                val_inputs = val_inputs.to(self.device)\n",
    "                val_labels = val_labels.to(self.device)\n",
    "                val_outputs = self(val_inputs)\n",
    "                val_outputs = (val_outputs >= 0.5).float()\n",
    "                value = soft_dice_coef(val_outputs, val_labels)\n",
    "                sample_num += val_labels.shape[0]\n",
    "                metric += value.cpu().numpy()\n",
    "\n",
    "            metric = metric / sample_num\n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "        origin = col_name\n",
    "        suffix = \"validate\"\n",
    "        if kwargs[\"apply\"] == \"local\":\n",
    "            suffix += \"_local\"\n",
    "        else:\n",
    "            suffix += \"_agg\"\n",
    "        tags = (\"metric\", suffix)\n",
    "        output_tensor_dict = {\n",
    "            TensorKey(\"dice_coef\", origin, round_num, True, tags): np.array(\n",
    "                metric\n",
    "            )\n",
    "        }\n",
    "        return output_tensor_dict, {}\n",
    "\n",
    "\n",
    "def optimizer(x): return torch.optim.Adam(x, 5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b909292",
   "metadata": {},
   "source": [
    "Our aggregation function. Here we use ExponentialSmoothingAveraging, you can take another from Federated_Pytorch_MNIST_custom_aggregation_Tutorial.ipynb or write your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8902570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialSmoothingAveraging(AggregationFunctionInterface):\n",
    "    \"\"\"\n",
    "        Averaging via exponential smoothing.\n",
    "\n",
    "        In order to use this mechanism properly you should specify\n",
    "        `aggregator.settings.db_store_rounds` in `override_config`\n",
    "        keyword argument of `run_experiment` function. It should be\n",
    "        equal to the number of rounds you want to include in smoothing window.\n",
    "\n",
    "        Args:\n",
    "            alpha(float): Smoothing term.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.9):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def call(self,\n",
    "             local_tensors,\n",
    "             db_iterator,\n",
    "             tensor_name,\n",
    "             fl_round,\n",
    "             tags):\n",
    "        \"\"\"Aggregate tensors.\n",
    "\n",
    "        Args:\n",
    "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
    "            db_iterator: iterator over history of all tensors.\n",
    "                Columns: ['tensor_name', 'round', 'tags', 'nparray']\n",
    "            tensor_name: name of the tensor\n",
    "            fl_round: round number\n",
    "            tags: tuple of tags for this tensor\n",
    "        \"\"\"\n",
    "        tensors, weights = zip(*[(x.tensor, x.weight) for x in local_tensors])\n",
    "        tensors, weights = np.array(tensors), np.array(weights)\n",
    "        average = np.average(tensors, weights=weights, axis=0)\n",
    "        if 'metric' in tags:\n",
    "            return average\n",
    "        previous_tensor_values = []\n",
    "        for record in db_iterator:\n",
    "            if (\n",
    "                record['tensor_name'] == tensor_name\n",
    "                and 'aggregated' in record['tags']\n",
    "                and 'delta' not in record['tags']\n",
    "            ):\n",
    "                previous_tensor_values.append(record['nparray'])\n",
    "        for i, x in enumerate(previous_tensor_values):\n",
    "            previous_tensor_values[i] = x * self.alpha * (1 - self.alpha) ** i\n",
    "        smoothing_term = np.sum(previous_tensor_values, axis=0)\n",
    "        return self.alpha * average + (1 - self.alpha) * smoothing_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-contemporary",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Create BraTSFederatedDataset, federated datasets for each collaborator will be created in `split()` method of this object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "welsh-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_data = BraTSFederatedDataset(batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-saturn",
   "metadata": {},
   "source": [
    "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with OpenFL. It provides built-in federated training function which will be used while training. Using its `setup` function, collaborator models and datasets can be automatically obtained for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "specific-railway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[20:14:46] </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                        <a href=\"file:///home/radionov/fork/brats/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:86</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fd75c3ea550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fl_model = FederatedModel(build_model=UNet3d, optimizer=optimizer,\n",
    "                          loss_fn=soft_dice_loss, data_loader=fl_data, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acquired-killer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[20:14:49] </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                        <a href=\"file:///home/radionov/fork/brats/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:86</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fd75c2dd358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[20:14:53] </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                        <a href=\"file:///home/radionov/fork/brats/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:86</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fd75c3314e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collaborator_models = fl_model.setup(num_collaborators=2, device='cpu')\n",
    "collaborators = {'one': collaborator_models[0], 'two': collaborator_models[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-samuel",
   "metadata": {},
   "source": [
    "We can see the current FL plan values by running the `fx.get_plan()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "infinite-toner",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"aggregator.settings.best_state_path\": \"save/torch_3dunet_brats_best.pbuf\",\n",
      "    \"aggregator.settings.db_store_rounds\": 1,\n",
      "    \"aggregator.settings.init_state_path\": \"save/torch_3dunet_brats_init.pbuf\",\n",
      "    \"aggregator.settings.last_state_path\": \"save/torch_3dunet_brats_last.pbuf\",\n",
      "    \"aggregator.settings.rounds_to_train\": 40,\n",
      "    \"aggregator.template\": \"openfl.component.Aggregator\",\n",
      "    \"assigner.settings.task_groups\": [\n",
      "        {\n",
      "            \"name\": \"train_and_validate\",\n",
      "            \"percentage\": 1.0,\n",
      "            \"tasks\": [\n",
      "                \"aggregated_model_validation\",\n",
      "                \"train\",\n",
      "                \"locally_tuned_model_validation\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"assigner.template\": \"openfl.component.RandomGroupedAssigner\",\n",
      "    \"collaborator.settings.db_store_rounds\": 1,\n",
      "    \"collaborator.settings.delta_updates\": false,\n",
      "    \"collaborator.settings.epochs_per_round\": 1.0,\n",
      "    \"collaborator.settings.opt_treatment\": \"RESET\",\n",
      "    \"collaborator.settings.polling_interval\": 4,\n",
      "    \"collaborator.template\": \"openfl.component.Collaborator\",\n",
      "    \"data_loader.settings.batch_size\": 8,\n",
      "    \"data_loader.settings.collaborator_count\": 2,\n",
      "    \"data_loader.settings.data_group_name\": \"brats\",\n",
      "    \"data_loader.template\": \"code.data_loader.PyTorchBraTSDataLoader\",\n",
      "    \"network.settings.agg_addr\": \"auto\",\n",
      "    \"network.settings.agg_port\": \"auto\",\n",
      "    \"network.settings.cert_folder\": \"cert\",\n",
      "    \"network.settings.client_reconnect_interval\": 5,\n",
      "    \"network.settings.disable_client_auth\": false,\n",
      "    \"network.settings.disable_tls\": false,\n",
      "    \"network.settings.hash_salt\": \"auto\",\n",
      "    \"network.template\": \"openfl.federation.Network\",\n",
      "    \"task_runner.device\": \"cpu\",\n",
      "    \"task_runner.settings.n_channels\": 4,\n",
      "    \"task_runner.settings.n_classes\": 3,\n",
      "    \"task_runner.template\": \"code.fed_3dunet_runner.PyTorchFederated3dUnet\",\n",
      "    \"tasks.aggregated_model_validation.function\": \"validate\",\n",
      "    \"tasks.aggregated_model_validation.kwargs\": {\n",
      "        \"apply\": \"global\",\n",
      "        \"metrics\": [\n",
      "            \"dice_coef\"\n",
      "        ],\n",
      "        \"use_tqdm\": true\n",
      "    },\n",
      "    \"tasks.locally_tuned_model_validation.function\": \"validate\",\n",
      "    \"tasks.locally_tuned_model_validation.kwargs\": {\n",
      "        \"apply\": \"local\",\n",
      "        \"metrics\": [\n",
      "            \"dice_coef\"\n",
      "        ],\n",
      "        \"use_tqdm\": true\n",
      "    },\n",
      "    \"tasks.settings\": {},\n",
      "    \"tasks.train.aggregation_type\": [\n",
      "        \"weighted_average\"\n",
      "    ],\n",
      "    \"tasks.train.function\": \"train_batches\",\n",
      "    \"tasks.train.kwargs\": {\n",
      "        \"metrics\": [\n",
      "            \"loss\"\n",
      "        ],\n",
      "        \"use_tqdm\": true\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(fx.get_plan())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-brooklyn",
   "metadata": {},
   "source": [
    "You can see common plan with all options. Lets concentrated on options directly related with federation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-sleep",
   "metadata": {},
   "source": [
    "`aggregator.settings.db_store_rounds` - rounds to store model weights.\n",
    "\n",
    "`aggregator.settings.rounds_to_train` - number of training rounds.\n",
    "\n",
    "`collaborator.settings.delta_updates` - sent only model delta (or full model if false)\n",
    "\n",
    "`collaborator.settings.opt_treatment` - the optimizer state treatment:<br>\n",
    "    RESET tells each collaborator to reset the optimizer state at the beginning\n",
    "    of each round.<br>\n",
    "    CONTINUE_LOCAL tells each collaborator to continue with the local optimizer\n",
    "    state from the previous round.<br>\n",
    "    CONTINUE_GLOBAL tells each collaborator to continue with the federally\n",
    "    averaged optimizer state from the previous round.\n",
    "    \n",
    "`tasks.train.aggregation_type` - aggregation function for current task. It maybe string with name of predefine openfl function like \"weighted_average\" or callable object of your own implementation like ExponentialSmoothingAveraging above. Default - \"weighted_average\", which related to np.average with weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-preparation",
   "metadata": {},
   "source": [
    "We can override this option by definnig overriding config and pass it to run_expirement function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "clinical-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To override  aggregator.settings.db_store_rounds\n",
    "# number of rounds\n",
    "override_config = {\n",
    "    'aggregator.settings.db_store_rounds': 2,\n",
    "    'aggregator.settings.rounds_to_train': 60,\n",
    "    'collaborator.settings.delta_updates': False,\n",
    "    'collaborator.settings.opt_treatment': \"RESET\",\n",
    "    'tasks.train.aggregation_type':        ExponentialSmoothingAveraging(0.9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-hundred",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run experiment, return trained FederatedModel\n",
    "final_fl_model = fx.run_experiment(\n",
    "    collaborators, override_config=override_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-michael",
   "metadata": {},
   "source": [
    "Lets validate final model on common validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-champagne",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = final_fl_model.model\n",
    "model.eval()\n",
    "device = final_fl_model.runner.device\n",
    "model.to(device)\n",
    "metric = 0.0\n",
    "sample_num = 0\n",
    "with torch.no_grad():\n",
    "    for collaborator in collaborator_models:\n",
    "        loader = collaborator.runner.data_loader.get_valid_loader()\n",
    "        for val_inputs, val_labels in tqdm(loader):\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_outputs = (val_outputs >= 0.5).float()\n",
    "            value = soft_dice_coef(val_outputs, val_labels)\n",
    "            sample_num += val_labels.shape[0]\n",
    "            metric += value.cpu().numpy()\n",
    "\n",
    "metric = metric / sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric for final model on whole validation dataset\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa8d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26b01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951d1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aging-recognition",
   "metadata": {},
   "source": [
    "Inference final model on test data. We should replace `generate_*_list` methods to pass test data to user datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "\n",
    "def generate_name_list(collaborator_count, collaborator_num, is_validation):\n",
    "    data_dir = './data/MICCAI_BraTS2020_TrainingData/'\n",
    "    data = [\n",
    "        {\n",
    "            'image1': data_dir + 'BraTS20_Training_'+str(i)[1:]+'/BraTS20_Training_'+str(i)[1:]+'_flair.nii.gz',\n",
    "            'image2': data_dir + 'BraTS20_Training_'+str(i)[1:]+'/BraTS20_Training_'+str(i)[1:]+'_t1ce.nii.gz',\n",
    "            'image3': data_dir + 'BraTS20_Training_'+str(i)[1:]+'/BraTS20_Training_'+str(i)[1:]+'_t1.nii.gz',\n",
    "            'image4': data_dir + 'BraTS20_Training_'+str(i)[1:]+'/BraTS20_Training_'+str(i)[1:]+'_t2.nii.gz',\n",
    "            'label': data_dir + 'BraTS20_Training_'+str(i)[1:]+'/BraTS20_Training_'+str(i)[1:]+'_seg.nii.gz'\n",
    "        } for i in range(1001, 1370)]\n",
    "    data = data[collaborator_num:: collaborator_count]\n",
    "    assert(len(data) > 8)\n",
    "    validation_size = len(data) // 8\n",
    "    if is_validation:\n",
    "        data = data[-validation_size:]\n",
    "    else:\n",
    "        data = data[: -validation_size]\n",
    "    return data\n",
    "\n",
    "\n",
    "def OUR_generate_train_list(self,  *args, **kwargs):\n",
    "    return generate_name_list(2, 1, False)\n",
    "\n",
    "# Take in attention, we create only 4 object in valid dataset\n",
    "\n",
    "\n",
    "def OUR_generate_val_list(self,  *args, **kwargs):\n",
    "    return generate_name_list(2, 1, True)[:4]  # create only 4 images\n",
    "\n",
    "\n",
    "# Replace functions:\n",
    "BraTSFederatedDataset.generate_train_list = OUR_generate_train_list\n",
    "BraTSFederatedDataset.generate_val_list = OUR_generate_val_list\n",
    "\n",
    "# Usual training process:\n",
    "fl_data2 = BraTSFederatedDataset(batch_size=6)\n",
    "fl_model2 = FederatedModel(build_model=UNet3d, optimizer=optimizer,\n",
    "                           loss_fn=soft_dice_loss, data_loader=fl_data2)\n",
    "collaborator_models2 = fl_model2.setup(num_collaborators=2)\n",
    "collaborators2 = {\n",
    "    'one': collaborator_models2[0], 'two': collaborator_models2[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just show how new collaborators work:\n",
    "for collaborator in collaborator_models2:\n",
    "    loader = collaborator.runner.data_loader.get_valid_loader()\n",
    "    for val_inputs, val_labels in tqdm(loader):\n",
    "        print(val_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get 4 - size batch, so this is our new data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
