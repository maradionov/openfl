{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "figured-aspect",
   "metadata": {},
   "source": [
    "# Federated PyTorch 3dUNET Tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-point",
   "metadata": {},
   "source": [
    " We will use MONAI brats [tutorial](https://github.com/Project-MONAI/tutorials/blob/master/3d_segmentation/brats_segmentation_3d.ipynb) as a template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "controlled-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "!python -c \"import torch\" || pip install torch\n",
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "iraqi-parameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Workspace Directories\n",
      "Creating Workspace Templates\n",
      "Successfully installed packages from /home/maksim/.local/workspace/requirements.txt.\n",
      "\n",
      "New workspace directory structure:\n",
      "workspace\n",
      "├── agg_to_col_one_signed_cert.zip\n",
      "├── code\n",
      "│   ├── data_loader.py\n",
      "│   ├── fed_unet_runner.py\n",
      "│   ├── pt_unet_parts.py\n",
      "│   ├── __init__.py\n",
      "│   └── fed_3dunet_runner.py\n",
      "├── plan\n",
      "│   ├── data.yaml\n",
      "│   ├── plan.yaml\n",
      "│   ├── cols.yaml\n",
      "│   └── defaults\n",
      "│       ├── aggregator.yaml\n",
      "│       ├── network.yaml\n",
      "│       ├── assigner.yaml\n",
      "│       ├── collaborator.yaml\n",
      "│       ├── tasks_torch.yaml\n",
      "│       ├── tasks_tensorflow.yaml\n",
      "│       ├── tasks_keras.yaml\n",
      "│       ├── tasks_fast_estimator.yaml\n",
      "│       ├── data_loader.yaml\n",
      "│       ├── task_runner.yaml\n",
      "│       └── defaults\n",
      "├── logs\n",
      "├── save\n",
      "│   ├── torch_unet_kvasir_init.pbuf\n",
      "│   ├── torch_unet_kvasir_last.pbuf\n",
      "│   └── torch_unet_kvasir_best.pbuf\n",
      "├── .workspace\n",
      "├── cert\n",
      "│   ├── ca\n",
      "│   │   ├── signing-ca\n",
      "│   │   ├── signing-ca.csr\n",
      "│   │   ├── root-ca\n",
      "│   │   ├── signing-ca.crt\n",
      "│   │   └── root-ca.crt\n",
      "│   ├── server\n",
      "│   │   ├── agg_maksim-thinkpad-t490.key\n",
      "│   │   ├── agg_none.csr\n",
      "│   │   ├── agg_maksim-thinkpad-t490.crt\n",
      "│   │   ├── agg_none.key\n",
      "│   │   ├── agg_maksim-thinkpad-t490.csr\n",
      "│   │   └── agg_none.crt\n",
      "│   ├── client\n",
      "│   │   ├── col_one.crt\n",
      "│   │   ├── col_two.crt\n",
      "│   │   ├── col_two.key\n",
      "│   │   └── col_one.key\n",
      "│   ├── cert_chain.crt\n",
      "│   ├── col_one.csr\n",
      "│   └── col_two.csr\n",
      "├── brats.tar\n",
      "├── agg_to_col_two_signed_cert.zip\n",
      "├── requirements.txt\n",
      "├── data\n",
      "│   └── Task01_BrainTumour\n",
      "│       ├── labelsTr\n",
      "│       ├── ._imagesTr\n",
      "│       ├── ._imagesTs\n",
      "│       ├── imagesTr\n",
      "│       ├── imagesTs\n",
      "│       ├── dataset.json\n",
      "│       └── ._labelsTr\n",
      "└── kvasir.zip\n",
      "\n",
      "16 directories, 48 files\n",
      "Setting Up Certificate Authority...\n",
      "\n",
      "1.  Create Root CA\n",
      "1.1 Create Directories\n",
      "1.2 Create Database\n",
      "1.3 Create CA Request and Certificate\n",
      "2.  Create Signing Certificate\n",
      "2.1 Create Directories\n",
      "2.2 Create Database\n",
      "2.3 Create Signing Certificate CSR\n",
      "2.4 Sign Signing Certificate CSR\n",
      "3   Create Certificate Chain\n",
      "\n",
      "Done.\n",
      "Creating AGGREGATOR certificate key pair with following settings: CN=\u001b[31mmaksim-thinkpad-t490\u001b[0m, SAN=\u001b[31mDNS:maksim-thinkpad-t490\u001b[0m\n",
      "  Writing AGGREGATOR certificate key pair to: \u001b[32mcert/server\u001b[0m\n",
      "The CSR Hash for file \u001b[32mserver/agg_maksim-thinkpad-t490.csr\u001b[0m = \u001b[31m31a5751b2da5dfe0d59b57cd86a18a72fe64baf07ce81c0ebf5553d4f6e9ce69bf27d1ee87806a94b41422469cd1d7e2\u001b[0m\n",
      " Signing AGGREGATOR certificate\n",
      "Creating COLLABORATOR certificate key pair with following settings: CN=\u001b[31mone\u001b[0m, SAN=\u001b[31mDNS:one\u001b[0m\n",
      "  Moving COLLABORATOR certificate to: \u001b[32mcert/col_one\u001b[0m\n",
      "The CSR Hash for file \u001b[32mcol_one.csr\u001b[0m = \u001b[31m73309d283c541e7686d2dc1d14a03dff18ebbd53c761f20fc30b754ec1f7b44c9539b03186e2ae9b15c50aa6887d5900\u001b[0m\n",
      " Signing COLLABORATOR certificate\n",
      "\n",
      "Registering \u001b[32mone\u001b[0m in \u001b[32mplan/cols.yaml\u001b[0m\n",
      "Creating COLLABORATOR certificate key pair with following settings: CN=\u001b[31mtwo\u001b[0m, SAN=\u001b[31mDNS:two\u001b[0m\n",
      "  Moving COLLABORATOR certificate to: \u001b[32mcert/col_two\u001b[0m\n",
      "The CSR Hash for file \u001b[32mcol_two.csr\u001b[0m = \u001b[31mb6bc2b3e2cc22347f2b7442afe0a934606b288e2440b81e91a7db69e7cebd771861a2fb76a14ffcc2d58cac0006ec5a9\u001b[0m\n",
      " Signing COLLABORATOR certificate\n",
      "\n",
      "Registering \u001b[32mtwo\u001b[0m in \u001b[32mplan/cols.yaml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import openfl.native as fx\n",
    "\n",
    "# Setup default workspace, logging, etc. Install additional requirements\n",
    "fx.init('torch_3dunet_brats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dirty-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from hashlib import sha384\n",
    "from os import path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from monai.data import DataLoader\n",
    "from monai.data import CacheDataset\n",
    "from monai.data import load_decathlon_datalist\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    CenterSpatialCropd,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    Spacingd,\n",
    "    ToTensord,\n",
    ")\n",
    "\n",
    "from openfl.federated import FederatedModel, FederatedDataSet\n",
    "from openfl.utilities import TensorKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-script",
   "metadata": {},
   "source": [
    "Download BraTS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -c --tries=0 --retry-connrefused --timeout=2 --wait=1  --continue \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task01_BrainTumour.tar\" -O brats.tar\n",
    "TAR_SHA384 = '049f8e1425d9e47a4cdabe03c5c2ff68aa01b6298a307'\\\n",
    "    '304638abd9b1341f0639d015357ca315d402984bc1cffa16bbf'\n",
    "assert sha384(open('./brats.tar', 'rb').read(\n",
    "    path.getsize('./brats.tar'))).hexdigest() == TAR_SHA384\n",
    "!tar -xvf brats.tar -C ./data\n",
    "!rm ./data/Task01_BrainTumour/imagesTr/.*.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-geneva",
   "metadata": {},
   "source": [
    "Prepare preprocessing function (just copy it from MONAI [tutorial](https://github.com/Project-MONAI/tutorials/blob/master/3d_segmentation/brats_segmentation_3d.ipynb)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pursuant-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi channels based on brats classes:\n",
    "    label 1 is the peritumoral edema\n",
    "    label 2 is the GD-enhancing tumor\n",
    "    label 3 is the necrotic and non-enhancing tumor core\n",
    "    The possible classes are TC (Tumor core), WT (Whole tumor)\n",
    "    and ET (Enhancing tumor).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            # merge label 2 and label 3 to construct TC\n",
    "            result.append(np.logical_or(d[key] == 2, d[key] == 3))\n",
    "            # merge labels 1, 2 and 3 to construct WT\n",
    "            result.append(\n",
    "                np.logical_or(\n",
    "                    np.logical_or(d[key] == 2, d[key] == 3), d[key] == 1\n",
    "                )\n",
    "            )\n",
    "            # label 2 is ET\n",
    "            result.append(d[key] == 2)\n",
    "            d[key] = np.stack(result, axis=0).astype(np.float32)\n",
    "        return d\n",
    "\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AsChannelFirstd(keys=\"image\"),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"], roi_size=[128, 128, 64], random_size=False\n",
    "        ),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=0.5),\n",
    "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=0.5),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AsChannelFirstd(keys=\"image\"),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=[128, 128, 64]),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-excuse",
   "metadata": {},
   "source": [
    "Lets define dataset, which will contain brain tumor images for one collaborator (train or validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "boolean-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSDataset(CacheDataset):\n",
    "    \"\"\"\n",
    "    This dataset contains brain tumor 3d images for one collaborator train or val.\n",
    "    Args:\n",
    "        collaborator_count: total number of collaborators\n",
    "        collaborator_num: number of current collaborator\n",
    "        is_validation: validation option\n",
    "        transform: transform sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, collaborator_count, collaborator_num, is_validation, transform):\n",
    "        self.is_validation = is_validation\n",
    "        dataset_dir = './data/Task01_BrainTumour/'\n",
    "\n",
    "        data = self._generate_data_list(dataset_dir)\n",
    "        # split all data for current collaborator\n",
    "        data = data[collaborator_num:: collaborator_count]\n",
    "        self.is_validation = is_validation\n",
    "        assert(len(data) > 8)\n",
    "        validation_size = len(data) // 8\n",
    "        if is_validation:\n",
    "            data = data[-validation_size:]\n",
    "        else:\n",
    "            data = data[: -validation_size]\n",
    "\n",
    "        super().__init__(data, transform, cache_num=1, num_workers=4)\n",
    "\n",
    "    def _generate_data_list(self, dataset_dir):\n",
    "        datalist = load_decathlon_datalist(os.path.join(\n",
    "            dataset_dir, \"dataset.json\"), True, \"training\")\n",
    "        return datalist\n",
    "\n",
    "    # define getitem to get only input and target tensors\n",
    "    def __getitem__(self, index):\n",
    "        tmp = super().__getitem__(index)\n",
    "        return (tmp['image'], tmp['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-dinner",
   "metadata": {},
   "source": [
    "Here we redefine `FederatedDataSet` methods, if we don't want to use default batch generator from `FederatedDataSet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "collectible-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSFederatedDataset(FederatedDataSet):\n",
    "    def __init__(self, collaborator_count=1, collaborator_num=0, batch_size=1, is_split=False, **kwargs):\n",
    "        \"\"\"Instantiate the federated data object\n",
    "        Args:\n",
    "            collaborator_count: total number of collaborators\n",
    "            collaborator_num: number of current collaborator\n",
    "            batch_size:  the batch size of the data loader\n",
    "            **kwargs: additional arguments, passed to super init\n",
    "        \"\"\"\n",
    "        super().__init__([], [], [], [], batch_size, num_classes=2, **kwargs)\n",
    "\n",
    "        self.collaborator_num = int(collaborator_num)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.training_set = BraTSDataset(\n",
    "            collaborator_count, collaborator_num, is_validation=False, transform=train_transform\n",
    "        )\n",
    "        self.valid_set = BraTSDataset(\n",
    "            collaborator_count, collaborator_num, is_validation=True, transform=val_transform\n",
    "        )\n",
    "\n",
    "        self.train_loader = self.get_train_loader()\n",
    "        self.val_loader = self.get_valid_loader()\n",
    "\n",
    "    def get_valid_loader(self, num_batches=None):\n",
    "        return DataLoader(self.valid_set, num_workers=2, batch_size=self.batch_size)\n",
    "\n",
    "    def get_train_loader(self, num_batches=None):\n",
    "        return DataLoader(\n",
    "            self.training_set, num_workers=2, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        return len(self.training_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        return len(self.valid_set)\n",
    "\n",
    "    def get_feature_shape(self):\n",
    "        return self.valid_set[0][0].shape\n",
    "\n",
    "    def split(self, collaborator_count, shuffle=True, equally=True):\n",
    "        return [\n",
    "            BraTSFederatedDataset(collaborator_count,\n",
    "                                  collaborator_num, self.batch_size)\n",
    "            for collaborator_num in range(collaborator_count)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-seeker",
   "metadata": {},
   "source": [
    "Our Unet model. Use MONAI UNet. Define validation function, to use special metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "lucky-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetWrapper(UNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            dimensions=3,\n",
    "            in_channels=4,\n",
    "            out_channels=3,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,)\n",
    "\n",
    "    def validate(\n",
    "        self, col_name, round_num, input_tensor_dict, use_tqdm=False, **kwargs\n",
    "    ):\n",
    "        \"\"\" Validate. Redifine function from PyTorchTaskRunner, to use our validation\"\"\"\n",
    "        self.rebuild_model(round_num, input_tensor_dict, validation=True)\n",
    "        loader = self.data_loader.get_valid_loader()\n",
    "        if use_tqdm:\n",
    "            loader = tqdm.tqdm(loader, desc=\"validate\")\n",
    "# -------------Usual validation code---------------------------------------------------------------------------\n",
    "        self.eval()\n",
    "        self.to(self.device)\n",
    "        dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "        post_trans = Compose(\n",
    "            [Activations(sigmoid=True), AsDiscrete(threshold_values=True)]\n",
    "        )\n",
    "        metric_sum = 0.0\n",
    "        metric_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in loader:\n",
    "                val_inputs = val_inputs.to(self.device)\n",
    "                val_labels = val_labels.to(self.device)\n",
    "                val_outputs = self(val_inputs)\n",
    "                val_outputs = post_trans(val_outputs)\n",
    "                # compute overall mean dice\n",
    "                value, not_nans = dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                not_nans = not_nans.item()\n",
    "                metric_count += not_nans\n",
    "                metric_sum += value.item() * not_nans\n",
    "\n",
    "            metric = metric_sum / metric_count\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "        origin = col_name\n",
    "        suffix = \"validate\"\n",
    "        if kwargs[\"apply\"] == \"local\":\n",
    "            suffix += \"_local\"\n",
    "        else:\n",
    "            suffix += \"_agg\"\n",
    "        tags = (\"metric\", suffix)\n",
    "        output_tensor_dict = {\n",
    "            TensorKey(\"dice_coef\", origin, round_num, True, tags): np.array(\n",
    "                metric\n",
    "            )\n",
    "        }\n",
    "        return output_tensor_dict, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-modem",
   "metadata": {},
   "source": [
    "Loss function and optimizer which will be passed to `FederatedModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "another-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper, because our train_batches set (output, target) args, but DiceLoss get (input, target)\n",
    "\n",
    "class DiceLossHeir(DiceLoss):\n",
    "    __name__ = 'DiceLoss'\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        return super().forward(input=output, target=target)\n",
    "\n",
    "\n",
    "loss_function = DiceLossHeir(\n",
    "    to_onehot_y=False, sigmoid=True, squared_pred=True)\n",
    "\n",
    "\n",
    "def optimizer(x): return torch.optim.Adam(\n",
    "    x, 1e-4, weight_decay=1e-5, amsgrad=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-contemporary",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Create BraTSFederatedDataset, federated datasets for collaborators will be created in `split()` method of this object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "welsh-nickname",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "fl_data = BraTSFederatedDataset(batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-saturn",
   "metadata": {},
   "source": [
    "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with OpenFL. It provides built-in federated training function which will be used while training. Using its `setup` function, collaborator models and datasets can be automatically obtained for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "specific-railway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[20:57:38] </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                        <a href=\"file:///home/maksim/.virtualenvs/brain_tumor/lib/python3.6/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:86</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fe7e7fe2278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fl_model = FederatedModel(build_model=UnetWrapper, optimizer=optimizer,\n",
    "                          loss_fn=loss_function, data_loader=fl_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acquired-killer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[20:57:47] </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                        <a href=\"file:///home/maksim/.virtualenvs/brain_tumor/lib/python3.6/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:86</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fe7e7ff0d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                        <a href=\"file:///home/maksim/.virtualenvs/brain_tumor/lib/python3.6/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:86</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fe7e7ed97b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collaborator_models = fl_model.setup(num_collaborators=2)\n",
    "collaborators = {'one': collaborator_models[0], 'two': collaborator_models[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-samuel",
   "metadata": {},
   "source": [
    "We can see the current FL plan values by running the `fx.get_plan()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "infinite-toner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"aggregator.settings.best_state_path\": \"save/torch_3dunet_brats_best.pbuf\",\n",
      "    \"aggregator.settings.db_store_rounds\": 1,\n",
      "    \"aggregator.settings.init_state_path\": \"save/torch_3dunet_brats_init.pbuf\",\n",
      "    \"aggregator.settings.last_state_path\": \"save/torch_3dunet_brats_last.pbuf\",\n",
      "    \"aggregator.settings.rounds_to_train\": 40,\n",
      "    \"aggregator.template\": \"openfl.component.Aggregator\",\n",
      "    \"assigner.settings.task_groups\": [\n",
      "        {\n",
      "            \"name\": \"train_and_validate\",\n",
      "            \"percentage\": 1.0,\n",
      "            \"tasks\": [\n",
      "                \"aggregated_model_validation\",\n",
      "                \"train\",\n",
      "                \"locally_tuned_model_validation\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"assigner.template\": \"openfl.component.RandomGroupedAssigner\",\n",
      "    \"collaborator.settings.db_store_rounds\": 1,\n",
      "    \"collaborator.settings.delta_updates\": false,\n",
      "    \"collaborator.settings.epochs_per_round\": 1.0,\n",
      "    \"collaborator.settings.opt_treatment\": \"RESET\",\n",
      "    \"collaborator.settings.polling_interval\": 4,\n",
      "    \"collaborator.template\": \"openfl.component.Collaborator\",\n",
      "    \"data_loader.settings.batch_size\": 4,\n",
      "    \"data_loader.settings.collaborator_count\": 2,\n",
      "    \"data_loader.settings.data_group_name\": \"brats\",\n",
      "    \"data_loader.template\": \"code.data_loader.PyTorchBraTSDataLoader\",\n",
      "    \"network.settings.agg_addr\": \"maksim-ThinkPad-T490\",\n",
      "    \"network.settings.agg_port\": 53419,\n",
      "    \"network.settings.cert_folder\": \"cert\",\n",
      "    \"network.settings.client_reconnect_interval\": 5,\n",
      "    \"network.settings.disable_client_auth\": false,\n",
      "    \"network.settings.disable_tls\": false,\n",
      "    \"network.settings.hash_salt\": \"auto\",\n",
      "    \"network.template\": \"openfl.federation.Network\",\n",
      "    \"task_runner.settings.n_channels\": 3,\n",
      "    \"task_runner.settings.n_classes\": 1,\n",
      "    \"task_runner.template\": \"code.fed_3dunet_runner.PyTorchFederated3dUnet\",\n",
      "    \"tasks.aggregated_model_validation.function\": \"validate\",\n",
      "    \"tasks.aggregated_model_validation.kwargs\": {\n",
      "        \"apply\": \"global\",\n",
      "        \"metrics\": [\n",
      "            \"dice_coef\"\n",
      "        ]\n",
      "    },\n",
      "    \"tasks.locally_tuned_model_validation.function\": \"validate\",\n",
      "    \"tasks.locally_tuned_model_validation.kwargs\": {\n",
      "        \"apply\": \"local\",\n",
      "        \"metrics\": [\n",
      "            \"dice_coef\"\n",
      "        ]\n",
      "    },\n",
      "    \"tasks.settings\": {},\n",
      "    \"tasks.train.function\": \"train_batches\",\n",
      "    \"tasks.train.kwargs\": {\n",
      "        \"metrics\": [\n",
      "            \"loss\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get the current values of the FL plan. Each of these can be overridden\n",
    "print(json.dumps(fx.get_plan(), indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-preparation",
   "metadata": {},
   "source": [
    "Now we are ready to run our experiment. If we want to pass in custom FL plan settings, we can easily do that with the `override_config` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-hundred",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run experiment, return trained FederatedModel\n",
    "final_fl_model = fx.run_experiment(\n",
    "    collaborators, override_config={'aggregator.settings.rounds_to_train': 30})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-michael",
   "metadata": {},
   "source": [
    "Lets validate final model on common validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = final_fl_model.model\n",
    "model.eval()\n",
    "device = final_fl_model.runner.device\n",
    "model.to(device)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "post_trans = Compose(\n",
    "    [Activations(sigmoid=True), AsDiscrete(threshold_values=True)]\n",
    ")\n",
    "metric_sum = 0.0\n",
    "metric_count = 0\n",
    "with torch.no_grad():\n",
    "    for collaborator in collaborator_models:\n",
    "        loader = collaborator.runner.data_loader.get_valid_loader()\n",
    "        for val_inputs, val_labels in tqdm(loader):\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_outputs = post_trans(val_outputs)\n",
    "            value, not_nans = dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "            not_nans = not_nans.item()\n",
    "            metric_count += not_nans\n",
    "            metric_sum += value.item() * not_nans\n",
    "\n",
    "metric = metric_sum / metric_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-gateway",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-reviewer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
