{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae8cbe16",
   "metadata": {},
   "source": [
    "# Federated PyTorch 3dUNET Tutorial\n",
    "## Using low-level Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06265729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "!pip install torchvision\n",
    "!pip install torch\n",
    "!pip install scikit-image\n",
    "!pip install dill\n",
    "!pip install nibabel \n",
    "!pip install cloudpickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0423e84d",
   "metadata": {},
   "source": [
    "### Describe the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76243ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from hashlib import sha384\n",
    "import PIL\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as tsf\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import random\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
    "from openfl.interface.interactive_api.federation import Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48658fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3dUNet model definition\n",
    "\"\"\"\n",
    "import torch\n",
    "from layers import soft_dice_loss, soft_dice_coef, DoubleConv, Down, Up, Out\n",
    "\n",
    "class UNet3d(nn.Module):\n",
    "    def __init__(self, in_channels=4, n_classes=3, n_channels=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, n_channels)\n",
    "        self.enc1 = Down(n_channels, 2 * n_channels)\n",
    "        self.enc2 = Down(2 * n_channels, 4 * n_channels)\n",
    "        self.enc3 = Down(4 * n_channels, 8 * n_channels)\n",
    "        self.enc4 = Down(8 * n_channels, 8 * n_channels)\n",
    "\n",
    "        self.dec1 = Up(16 * n_channels, 4 * n_channels)\n",
    "        self.dec2 = Up(8 * n_channels, 2 * n_channels)\n",
    "        self.dec3 = Up(4 * n_channels, n_channels)\n",
    "        self.dec4 = Up(2 * n_channels, n_channels)\n",
    "        self.out = Out(n_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv(x)\n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        x5 = self.enc4(x4)\n",
    "\n",
    "        mask = self.dec1(x5, x4)\n",
    "        mask = self.dec2(mask, x3)\n",
    "        mask = self.dec3(mask, x2)\n",
    "        mask = self.dec4(mask, x1)\n",
    "        mask = self.out(mask)\n",
    "        mask = torch.sigmoid(mask)\n",
    "\n",
    "        return mask\n",
    "    \n",
    "model_unet = UNet3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1731494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_adam = optim.Adam(model_unet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d391716a",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4d74b",
   "metadata": {},
   "source": [
    "We ask user to keep all the test data in `data/` folder under the workspace as it will not be sent to collaborators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872ea93",
   "metadata": {},
   "source": [
    "Path to brats dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a73be26a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!cp ~/brain_tumor/MICCAI_BraTS2020_TrainingData ./data/ -r\n",
    "BRATS_PATH = './data/MICCAI_BraTS2020_TrainingData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c66012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSDataset():\n",
    "    \"\"\"\n",
    "    This dataset contains brain tumor 3d images for one collaborator train or val.\n",
    "    Args:\n",
    "        data_list: list of image paths\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        images = []\n",
    "        for i in range(1, 5):\n",
    "            img = nib.load(self.data_list[index]['image{}'.format(i)])\n",
    "            img = np.asanyarray(img.dataobj)\n",
    "            img = self.resize(img, (160, 160, 128))\n",
    "            img = self.normalize(img)\n",
    "            images.append(img)\n",
    "        img = np.stack(images)\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        mask = nib.load(self.data_list[index]['label'])\n",
    "        mask = np.asanyarray(mask.dataobj)\n",
    "        mask = self.resize(mask, (160, 160, 128)).astype(np.uint8)\n",
    "        mask = self.classify(mask)\n",
    "        return (img, mask)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        data_min = np.min(data)\n",
    "        return (data - data_min) / (np.max(data) - data_min)\n",
    "\n",
    "    def resize(self, data, sizes):\n",
    "        data = resize(data, sizes, mode='edge',\n",
    "                      anti_aliasing=False,\n",
    "                      anti_aliasing_sigma=None,\n",
    "                      preserve_range=True,\n",
    "                      order=0)\n",
    "        return data\n",
    "\n",
    "    def classify(self, inputs):\n",
    "        result = []\n",
    "        # merge label 2 and label 3 to construct TC\n",
    "        result.append(np.logical_or(inputs == 2, inputs == 3))\n",
    "        # merge labels 1, 2 and 3 to construct WT\n",
    "        result.append(\n",
    "            np.logical_or(\n",
    "                np.logical_or(inputs == 2, inputs == 3), inputs == 1\n",
    "            )\n",
    "        )\n",
    "        # label 2 is ET\n",
    "        result.append(inputs == 2)\n",
    "        return np.stack(result, axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae266f6b",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf0d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model_unet, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model_unet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de15238",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b36ada0",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class FedDataset(DataInterface):\n",
    "    # Use class atribute to shufle once.\n",
    "    data_list = [\n",
    "        {\n",
    "            'image1': BRATS_PATH + 'BraTS20_Training_'+str(i)[1:]+'/BraTS20_Training_'+str(i)[1:]+'_flair.nii.gz',\n",
    "            'image2': BRATS_PATH + 'BraTS20_Training_'+str(i)[1:]+'/BraTS20_Training_'+str(i)[1:]+'_t1ce.nii.gz',\n",
    "            'image3': BRATS_PATH + 'BraTS20_Training_'+str(i)[1:]+'/BraTS20_Training_'+str(i)[1:]+'_t1.nii.gz',\n",
    "            'image4': BRATS_PATH + 'BraTS20_Training_'+str(i)[1:]+'/BraTS20_Training_'+str(i)[1:]+'_t2.nii.gz',\n",
    "            'label': BRATS_PATH + 'BraTS20_Training_'+str(i)[1:]+'/BraTS20_Training_'+str(i)[1:]+'_seg.nii.gz'\n",
    "        } for i in range(1001, 1370)]\n",
    "    random.shuffle(data_list)\n",
    "\n",
    "    def __init__(self, UserDatasetClass, **kwargs):\n",
    "        self.UserDatasetClass = UserDatasetClass\n",
    "        self.kwargs = kwargs\n",
    "    # def __init__(self, collaborator_count=1, collaborator_num=0, batch_size=1, data_list=[], **kwargs):\n",
    "\n",
    "    def _delayed_init(self, data_path='1,1'):\n",
    "        self.rank, self.world_size = [int(part)\n",
    "                                      for part in data_path.split(',')]\n",
    "\n",
    "        self.train_list = self.generate_train_list(self.world_size, self.rank)\n",
    "        self.val_list = self.generate_val_list(self.world_size, self.rank)\n",
    "\n",
    "        self.train_set = self.UserDatasetClass(self.train_list)\n",
    "        self.valid_set = self.UserDatasetClass(self.val_list)\n",
    "\n",
    "    def generate_name_list(self, collaborator_count, collaborator_num, is_validation):\n",
    "        # split all data for current collaborator\n",
    "        data = getattr(self, 'data_list')[\n",
    "            collaborator_num:: collaborator_count]\n",
    "        data = data\n",
    "        assert(len(data) > 7)\n",
    "        validation_size = len(data) // 7\n",
    "        if is_validation:\n",
    "            data = data[-validation_size:]\n",
    "        else:\n",
    "            data = data[: -validation_size]\n",
    "        return data\n",
    "\n",
    "    def generate_train_list(self, collaborator_count, collaborator_num, *args, **kwargs):\n",
    "        return self.generate_name_list(collaborator_count, collaborator_num, False)\n",
    "\n",
    "    def generate_val_list(self, collaborator_count, collaborator_num, *args, **kwargs):\n",
    "        return self.generate_name_list(collaborator_count, collaborator_num, True)\n",
    "\n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.train_set, num_workers=8, batch_size=self.kwargs['train_bs'], shuffle=True\n",
    "        )\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(self.valid_set, num_workers=8, batch_size=self.kwargs['valid_bs'])\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f733cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = FedDataset(BraTSDataset, train_bs=3, valid_bs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68940161",
   "metadata": {},
   "source": [
    "### Register tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e94ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "TI = TaskInterface()\n",
    "\n",
    "\n",
    "@TI.register_fl_task(model='unet_model', data_loader='train_loader',\n",
    "                     device='device', optimizer='optimizer')\n",
    "def train(unet_model, train_loader, optimizer, device, loss_fn=soft_dice_loss, some_parameter=None):\n",
    "    if not torch.cuda.is_available():\n",
    "        device = 'cpu'\n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "\n",
    "    unet_model.train()\n",
    "    unet_model.to(device)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
    "            target).to(device, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        output = unet_model(data)\n",
    "        loss = loss_fn(output=output, target=target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    return {'train_loss': np.mean(losses), }\n",
    "\n",
    "\n",
    "@TI.register_fl_task(model='unet_model', data_loader='val_loader', device='device')\n",
    "def validate(unet_model, val_loader, device):\n",
    "    unet_model.eval()\n",
    "    unet_model.to(device)\n",
    "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "    metric = 0.0\n",
    "    sample_num = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            val_outputs = unet_model(val_inputs)\n",
    "            val_outputs = (val_outputs >= 0.5).float()\n",
    "            value = soft_dice_coef(val_outputs, val_labels)\n",
    "            sample_num += val_labels.shape[0]\n",
    "            metric += value.cpu().numpy()\n",
    "\n",
    "    return {'dice_coef': metric / sample_num}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9404f40",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4503539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "\n",
    "federation = Federation(central_node_fqdn='localhost', disable_tls=True)\n",
    "\n",
    "# First number which is a collaborators rank is also passed as a cuda device identifier\n",
    "col_data_paths = {'one': '1,1'}#, 'two': '2,2'}\n",
    "federation.register_collaborators(col_data_paths=col_data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f89a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "fl_experiment = FLExperiment(federation=federation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c31dba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tried to remove tensor: __opt_state_needed not present in the tensor dict\n",
      "tried to remove tensor: __opt_state_needed not present in the tensor dict\n",
      "gRPC is running on insecure channel with TLS disabled.\n"
     ]
    }
   ],
   "source": [
    "# If I use autoreload I got a pickling error\n",
    "\n",
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "# Redefine some parametrs\n",
    "fl_experiment.prepare_workspace_distribution(model_provider=MI,\n",
    "                                             task_keeper=TI,\n",
    "                                             data_loader=fed_dataset,\n",
    "                                             rounds_to_train=2,\n",
    "                                             opt_treatment='CONTINUE_GLOBAL')\n",
    "# This command starts the aggregator server\n",
    "fl_experiment.start_experiment(model_provider=MI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95115023",
   "metadata": {},
   "source": [
    "## Now we validate the best model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d2870",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = fl_experiment.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f01ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset._delayed_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9088cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating initial model\n",
    "validate(initial_model, fed_dataset.get_valid_loader(), 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0289ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating trained model\n",
    "validate(best_model, fed_dataset.get_valid_loader(), 'cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
